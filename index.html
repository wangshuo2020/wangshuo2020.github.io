<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     畅院士的开山大弟子的博客
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/main.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

</head>

</html>

<body>
  <div id="app">
    <main class="content">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/Shen-Yu/hexo-theme-ayer"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">畅院士的开山大弟子的博客</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>

<div id="main">
  <section class="outer">
  <article class="articles">
    
    
    
    
    <article id="post-voc-yolo相互转换" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/22/voc-yolo%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2/"
    >voc/yolo相互转换</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/22/voc-yolo%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2/" class="article-date">
  <time datetime="2020-03-22T13:46:13.000Z" itemprop="datePublished">2020-03-22</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>voc转yolo：<br>在目录下新建VOC2007，并在VOC2007下新建Annotations，ImageSets和JPEGImages三个文件夹。在ImageSets下新建Main文件夹。文件目录如下所示：<br>|——VOC2007<br>|————Annotations<br>|————ImageSets<br>|——————Main<br>|————JPEGImages<br>将自己的数据集图片拷贝到JPEGImages目录下。将数据集label文件拷贝到Annotations目录下。在VOC2007下新建voc_to_yolo.py文件夹，将下面代码拷贝进去运行，将生成四个文件：train.txt,val.txt,test.txt和trainval.txt。数据集label文件就是图片对应的xml文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">trainval_percent &#x3D; 0.1</span><br><span class="line">train_percent &#x3D; 0.9</span><br><span class="line">xmlfilepath &#x3D; &#39;Annotations&#39;</span><br><span class="line">txtsavepath &#x3D; &#39;ImageSets\Main&#39;</span><br><span class="line">total_xml &#x3D; os.listdir(xmlfilepath)</span><br><span class="line"></span><br><span class="line">num &#x3D; len(total_xml)</span><br><span class="line">list &#x3D; range(num)</span><br><span class="line">tv &#x3D; int(num * trainval_percent)</span><br><span class="line">tr &#x3D; int(tv * train_percent)</span><br><span class="line">trainval &#x3D; random.sample(list, tv)</span><br><span class="line">train &#x3D; random.sample(trainval, tr)</span><br><span class="line"></span><br><span class="line">ftrainval &#x3D; open(&#39;ImageSets&#x2F;Main&#x2F;trainval.txt&#39;, &#39;w&#39;)</span><br><span class="line">ftest &#x3D; open(&#39;ImageSets&#x2F;Main&#x2F;test.txt&#39;, &#39;w&#39;)</span><br><span class="line">ftrain &#x3D; open(&#39;ImageSets&#x2F;Main&#x2F;train.txt&#39;, &#39;w&#39;)</span><br><span class="line">fval &#x3D; open(&#39;ImageSets&#x2F;Main&#x2F;val.txt&#39;, &#39;w&#39;)</span><br><span class="line"></span><br><span class="line">for i in list:</span><br><span class="line">    name &#x3D; total_xml[i][:-4] + &#39;\n&#39;</span><br><span class="line">    if i in trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        if i in train:</span><br><span class="line">            ftest.write(name)</span><br><span class="line">        else:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    else:</span><br><span class="line">        ftrain.write(name)</span><br><span class="line"></span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest.close()</span><br></pre></td></tr></table></figure>
<p>代码执行结果会在Main文件夹下生成四个txt文件，分别是test.txt,train.txt,trainval.txt,val.txt。</p>
<p>yolo转voc：<br>未完待续</p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-gpu-cdnnn-cuda版本对应关系" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/22/gpu-cdnnn-cuda%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB/"
    >gpu cdnnn cuda版本对应关系</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/22/gpu-cdnnn-cuda%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB/" class="article-date">
  <time datetime="2020-03-22T10:05:14.000Z" itemprop="datePublished">2020-03-22</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      
      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-object-detection-api" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/22/object-detection-api/"
    >object detection api</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/22/object-detection-api/" class="article-date">
  <time datetime="2020-03-22T10:01:13.000Z" itemprop="datePublished">2020-03-22</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>首先，建议一种配置环境：<br>    anaconda(python3.6)、tensorflow_gpu==1.14.0、cudnn 7.4、cuda 10。因为tensorflow(1.12/1.13/2.0)都存在不兼容问题。<br>    tensorflow1.12版本与cudnn7.4、cuda10不兼容。1.13版本v1模块中没有v2属性。2.x版本tensorflow没有contrib属性。原因是tensorflow更新的太快，object detection api跟不上tensorflow的更新速度。<br>安装流程：<br>    1、到(<a href="https://github.com/tensorflow/models" target="_blank" rel="noopener">https://github.com/tensorflow/models</a>) download zip。<br>    2、创建虚拟环境，执行如下指令。<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">··· conda create -n tensorflow1 pip python&#x3D;3.6</span><br></pre></td></tr></table></figure><br>    3、激活虚拟环境并安装tensorflow_gpu==1.14.0版本：<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --ignore-installed --upgrade tensorflow-gpu&#x3D;&#x3D;1.14.0</span><br></pre></td></tr></table></figure><br>    4、安装一些别的包，配置API的依赖项<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pip install pillow</span><br><span class="line">pip install lxml</span><br><span class="line">pip install Cython</span><br><span class="line">pip install jupyter</span><br><span class="line">pip install matplotlib</span><br><span class="line">pip install pandas</span><br><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure><br>    5、到(<a href="https://github.com/protocolbuffers/protobuf/releases)下载protoc-x.xx.x-win64.zip。解压后将protoc.exe文件拷贝到C:\Windows路径下。" target="_blank" rel="noopener">https://github.com/protocolbuffers/protobuf/releases)下载protoc-x.xx.x-win64.zip。解压后将protoc.exe文件拷贝到C:\Windows路径下。</a><br>    6、配置API的环境变量，即在系统变量中新建一个名为PYTHONPATH的变量，值为.\models;.\models\research;.\models\research\slim。注意环境变量中反斜线的方向。<br>    7、编译Protobuf:<br>        在research目录下打开cmd，执行如下指令：<br>        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protoc --python_out&#x3D;. .\object_detection\protos\anchor_generator.proto .\object_detection\protos\argmax_matcher.proto .\object_detection\protos\bipartite_matcher.proto .\object_detection\protos\box_coder.proto .\object_detection\protos\box_predictor.proto .\object_detection\protos\eval.proto .\object_detection\protos\faster_rcnn.proto .\object_detection\protos\faster_rcnn_box_coder.proto .\object_detection\protos\grid_anchor_generator.proto .\object_detection\protos\hyperparams.proto .\object_detection\protos\image_resizer.proto .\object_detection\protos\input_reader.proto .\object_detection\protos\losses.proto .\object_detection\protos\matcher.proto .\object_detection\protos\mean_stddev_box_coder.proto .\object_detection\protos\model.proto .\object_detection\protos\optimizer.proto .\object_detection\protos\pipeline.proto .\object_detection\protos\post_processing.proto .\object_detection\protos\preprocessor.proto .\object_detection\protos\region_similarity_calculator.proto .\object_detection\protos\square_box_coder.proto .\object_detection\protos\ssd.proto .\object_detection\protos\ssd_anchor_generator.proto .\object_detection\protos\string_int_label_map.proto .\object_detection\protos\train.proto .\object_detection\protos\keypoint_box_coder.proto .\object_detection\protos\multiscale_anchor_generator.proto .\object_detection\protos\graph_rewriter.proto .\object_detection\protos\calibration.proto .\object_detection\protos\flexible_grid_anchor_generator.proto</span><br></pre></td></tr></table></figure><br>        注：在protos目录下的所有proto文件都要编译，否则就会报错，如果报错就检查哪个proto文件没有编译。<br>    8、执行如下指令:<br>       <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure><br>    9、判断API是否安装成功：<br>       在builders目录下打开cmd，执行指令：<br>       <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python model_builder_test.py</span><br></pre></td></tr></table></figure><br>       如果显示OK，说明安装成功。<br>    注：1、如果在升级tensorflow版本的时候出现Cannot uninstall ‘wrapt’的提示，直接去手动删除就可以了。<br>        2、如果想打开一个不在jupyter根目录的文件，那么就直接在这个目录进入cmd，输入jupyter notebook就可以了。</p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-VOC数据集" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/22/VOC%E6%95%B0%E6%8D%AE%E9%9B%86/"
    >VOC数据集</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/22/VOC%E6%95%B0%E6%8D%AE%E9%9B%86/" class="article-date">
  <time datetime="2020-03-22T01:54:51.000Z" itemprop="datePublished">2020-03-22</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>数据集的标注：<br>数据集的标注很谨慎，有专门的标注团队，并遵从统一的标注标准。<br>VOC数据集的标注信息是用xml文件组织的，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;annotation&gt;</span><br><span class="line">	&lt;folder&gt;Desktop&lt;&#x2F;folder&gt;</span><br><span class="line">	&lt;filename&gt;fd3f06748e6cb31a564800c740ec8ce.png&lt;&#x2F;filename&gt;</span><br><span class="line">	&lt;path&gt;C:\Users\Administrator\Desktop\fd3f06748e6cb31a564800c740ec8ce.png&lt;&#x2F;path&gt;</span><br><span class="line">	&lt;source&gt;</span><br><span class="line">		&lt;database&gt;Unknown&lt;&#x2F;database&gt;</span><br><span class="line">	&lt;&#x2F;source&gt;</span><br><span class="line">	&lt;size&gt;</span><br><span class="line">		&lt;width&gt;1920&lt;&#x2F;width&gt;</span><br><span class="line">		&lt;height&gt;943&lt;&#x2F;height&gt;</span><br><span class="line">		&lt;depth&gt;3&lt;&#x2F;depth&gt;</span><br><span class="line">	&lt;&#x2F;size&gt;</span><br><span class="line">	&lt;segmented&gt;0&lt;&#x2F;segmented&gt;</span><br><span class="line">	&lt;object&gt;</span><br><span class="line">		&lt;name&gt;dog&lt;&#x2F;name&gt;</span><br><span class="line">		&lt;pose&gt;Unspecified&lt;&#x2F;pose&gt;</span><br><span class="line">		&lt;truncated&gt;0&lt;&#x2F;truncated&gt;</span><br><span class="line">		&lt;difficult&gt;0&lt;&#x2F;difficult&gt;</span><br><span class="line">		&lt;bndbox&gt;</span><br><span class="line">			&lt;xmin&gt;440&lt;&#x2F;xmin&gt;</span><br><span class="line">			&lt;ymin&gt;142&lt;&#x2F;ymin&gt;</span><br><span class="line">			&lt;xmax&gt;1231&lt;&#x2F;xmax&gt;</span><br><span class="line">			&lt;ymax&gt;612&lt;&#x2F;ymax&gt;</span><br><span class="line">		&lt;&#x2F;bndbox&gt;</span><br><span class="line">	&lt;&#x2F;object&gt;</span><br><span class="line">&lt;&#x2F;annotation&gt;</span><br></pre></td></tr></table></figure>
<p>filename ：文件名<br>source，owner：图片来源，及拥有者(现在版本的labelImg好像不标注owner了)<br>size：图片大小<br>segmented：是否分割<br>object：目标的相关信息<br>        name：object名称，20个类别<br>        pose：拍摄角度：front, rear, left, right, unspecified<br>        truncated：目标是否被截断（比如在图片之外），或者被遮挡（超过15%）<br>        difficult：检测难易程度，这个主要是根据目标的大小，光照变化，图片质量来判断<br>        bndbox：bounding box的左上角点和右下角点的4个坐标值。</p>
<p>数据集组织结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">├── Annotations 进行detection 任务时的 标签文件，xml文件形式</span><br><span class="line">├── ImageSets 存放数据集的分割文件，比如train，val，test</span><br><span class="line">├── JPEGImages 存放.jpg格式的图片文件</span><br><span class="line">├── SegmentationClass 存放按照class分割的图片</span><br><span class="line">└── SegmentationObject 存放按照object分割的图片</span><br></pre></td></tr></table></figure>

<p>Annotations文件夹：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">├── 000001.xml</span><br><span class="line">├── 000002.xml</span><br><span class="line">├── 000003.xml</span><br><span class="line">├── 000004.xml</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">├── 009962.xml</span><br><span class="line">└── 009963.xml</span><br></pre></td></tr></table></figure>

<p>ImageSets文件夹：<br>存放数据集的分割文件，包含三个子文件夹Layout，Main，Segmentation，其中Main文件夹存放的是用于分类和检测的数据集分割文件，Layout文件夹用于person layout任务，Segmentation用于分割任务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">├── Layout</span><br><span class="line">│   ├── test.txt</span><br><span class="line">│   ├── train.txt</span><br><span class="line">│   ├── trainval.txt</span><br><span class="line">│   └── val.txt</span><br><span class="line">├── Main</span><br><span class="line">│   ├── aeroplane_test.txt</span><br><span class="line">│   ├── aeroplane_train.txt</span><br><span class="line">│   ├── aeroplane_trainval.txt</span><br><span class="line">│   ├── aeroplane_val.txt</span><br><span class="line">│   ├── bicycle_test.txt</span><br><span class="line">│   ├── bicycle_train.txt</span><br><span class="line">│   ├── bicycle_trainval.txt</span><br><span class="line">│   ├── bicycle_val.txt</span><br><span class="line">│   ├── bird_test.txt</span><br><span class="line">│   ├── bird_train.txt</span><br><span class="line">│   ├── bird_trainval.txt</span><br><span class="line">│   ├── bird_val.txt</span><br><span class="line">│   ├── boat_test.txt</span><br><span class="line">│   ├── boat_train.txt</span><br><span class="line">│   ├── boat_trainval.txt</span><br><span class="line">│   ├── boat_val.txt</span><br><span class="line">│   ├── bottle_test.txt</span><br><span class="line">│   ├── bottle_train.txt</span><br><span class="line">│   ├── bottle_trainval.txt</span><br><span class="line">│   ├── bottle_val.txt</span><br><span class="line">│   ├── bus_test.txt</span><br><span class="line">│   ├── bus_train.txt</span><br><span class="line">│   ├── bus_trainval.txt</span><br><span class="line">│   ├── bus_val.txt</span><br><span class="line">│   ├── car_test.txt</span><br><span class="line">│   ├── car_train.txt</span><br><span class="line">│   ├── car_trainval.txt</span><br><span class="line">│   ├── car_val.txt</span><br><span class="line">│   ├── cat_test.txt</span><br><span class="line">│   ├── cat_train.txt</span><br><span class="line">│   ├── cat_trainval.txt</span><br><span class="line">│   ├── cat_val.txt</span><br><span class="line">│   ├── chair_test.txt</span><br><span class="line">│   ├── chair_train.txt</span><br><span class="line">│   ├── chair_trainval.txt</span><br><span class="line">│   ├── chair_val.txt</span><br><span class="line">│   ├── cow_test.txt</span><br><span class="line">│   ├── cow_train.txt</span><br><span class="line">│   ├── cow_trainval.txt</span><br><span class="line">│   ├── cow_val.txt</span><br><span class="line">│   ├── diningtable_test.txt</span><br><span class="line">│   ├── diningtable_train.txt</span><br><span class="line">│   ├── diningtable_trainval.txt</span><br><span class="line">│   ├── diningtable_val.txt</span><br><span class="line">│   ├── dog_test.txt</span><br><span class="line">│   ├── dog_train.txt</span><br><span class="line">│   ├── dog_trainval.txt</span><br><span class="line">│   ├── dog_val.txt</span><br><span class="line">│   ├── horse_test.txt</span><br><span class="line">│   ├── horse_train.txt</span><br><span class="line">│   ├── horse_trainval.txt</span><br><span class="line">│   ├── horse_val.txt</span><br><span class="line">│   ├── motorbike_test.txt</span><br><span class="line">│   ├── motorbike_train.txt</span><br><span class="line">│   ├── motorbike_trainval.txt</span><br><span class="line">│   ├── motorbike_val.txt</span><br><span class="line">│   ├── person_test.txt</span><br><span class="line">│   ├── person_train.txt</span><br><span class="line">│   ├── person_trainval.txt</span><br><span class="line">│   ├── person_val.txt</span><br><span class="line">│   ├── pottedplant_test.txt</span><br><span class="line">│   ├── pottedplant_train.txt</span><br><span class="line">│   ├── pottedplant_trainval.txt</span><br><span class="line">│   ├── pottedplant_val.txt</span><br><span class="line">│   ├── sheep_test.txt</span><br><span class="line">│   ├── sheep_train.txt</span><br><span class="line">│   ├── sheep_trainval.txt</span><br><span class="line">│   ├── sheep_val.txt</span><br><span class="line">│   ├── sofa_test.txt</span><br><span class="line">│   ├── sofa_train.txt</span><br><span class="line">│   ├── sofa_trainval.txt</span><br><span class="line">│   ├── sofa_val.txt</span><br><span class="line">│   ├── test.txt</span><br><span class="line">│   ├── train_test.txt</span><br><span class="line">│   ├── train_train.txt</span><br><span class="line">│   ├── train_trainval.txt</span><br><span class="line">│   ├── train.txt</span><br><span class="line">│   ├── train_val.txt</span><br><span class="line">│   ├── trainval.txt</span><br><span class="line">│   ├── tvmonitor_test.txt</span><br><span class="line">│   ├── tvmonitor_train.txt</span><br><span class="line">│   ├── tvmonitor_trainval.txt</span><br><span class="line">│   ├── tvmonitor_val.txt</span><br><span class="line">│   └── val.txt</span><br><span class="line">└── Segmentation</span><br><span class="line">    ├── test.txt</span><br><span class="line">    ├── train.txt</span><br><span class="line">    ├── trainval.txt</span><br><span class="line">    └── val.txt</span><br></pre></td></tr></table></figure>

<p>主要介绍一下Main文件夹中的组织结构，先来看以下这几个文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">├── Main</span><br><span class="line">│   ├── train.txt 写着用于训练的图片名称 共2501个</span><br><span class="line">│   ├── val.txt 写着用于验证的图片名称 共2510个</span><br><span class="line">│   ├── trainval.txt train与val的合集 共5011个</span><br><span class="line">│   ├── test.txt 写着用于测试的图片名称 共4952个</span><br></pre></td></tr></table></figure>

<p>里面的文件内容是下面这样的：以train.txt文件为例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">000012</span><br><span class="line">000017</span><br><span class="line">000023</span><br><span class="line">000026</span><br><span class="line">000032</span><br><span class="line">000033</span><br><span class="line">000034</span><br><span class="line">000035</span><br><span class="line">000036</span><br><span class="line">000042</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">009949</span><br><span class="line">009959</span><br><span class="line">009961</span><br></pre></td></tr></table></figure>
<p>就是对数据库的分割，这一部分图片用于train，其他的用作val，test等。</p>
<p>Main中剩下的文件就是每一类别在train或val或test中的ground truth，这个ground truth是为了方便classification任务而提供的；如果是detection的话，使用的是上面的xml标签文件。<br>ground truth的意思是经过正确标注的数据。因此不严谨标注的数据不能称为ground truth。可以理解为标注的标准答案。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">├── Main</span><br><span class="line">│   ├── aeroplane_test.txt 写着用于训练的图片名称 共2501个，指定正负样本</span><br><span class="line">│   ├── aeroplane_train.txt 写着用于验证的图片名称 共2510个，指定正负样本</span><br><span class="line">│   ├── aeroplane_trainval.txt train与val的合集 共5011个，指定正负样本</span><br><span class="line">│   ├── aeroplane_val.txt 写着用于测试的图片名称 共4952个，指定正负样本</span><br><span class="line">……</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

<p>里面文件是这样的（以aeroplane_train.txt为例）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">000012 -1</span><br><span class="line">000017 -1</span><br><span class="line">000023 -1</span><br><span class="line">000026 -1</span><br><span class="line">000032  1</span><br><span class="line">000033  1</span><br><span class="line">000034 -1</span><br><span class="line">000035 -1</span><br><span class="line">000036 -1</span><br><span class="line">000042 -1</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">009949 -1</span><br><span class="line">009959 -1</span><br><span class="line">009961 -1</span><br></pre></td></tr></table></figure>

<p>前面一列是训练集中的图片名称，这一列跟train.txt文件中的内容是一样的，后面一列是标签，即训练集中这张图片是不是aeroplane，是的话为1，否则为-1.<br>其他所有的(class)_(imgset).txt文件都是类似的。<br>    (class)_train存放的是训练使用的数据，每一个class都有2501个train数据。<br>    (class)_val 存放的是验证使用的数据，每一个class都有2510个val数据。<br>    (class)_trainval 将上面两个进行了合并，每一个class有5011个数据。<br>    (class)_test 存放的是测试使用的数据，每一个class有4952个test数据。</p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-LabelImg" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/21/LabelImg/"
    >LabelImg</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/21/LabelImg/" class="article-date">
  <time datetime="2020-03-21T03:24:52.000Z" itemprop="datePublished">2020-03-21</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>安装：<br>1.安装anaconda(python3.6);<br>2.到<a href="https://github.com/tzutalin/labelImg" target="_blank" rel="noopener">labelImg</a> download zip;<br>3.打开Anaconda Prompt，进入labelImg根目录，输入命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install pyqt&#x3D;5 </span><br><span class="line">pyrcc5 -o libs&#x2F;resources.py resources.qrc</span><br><span class="line">python labelImg.py</span><br></pre></td></tr></table></figure>
<p>conda国内源的配置：<br>只需要修改C:\Users\Administrator目录下的.condarc文件。Windows用户无法直接创建名为.condarc的文件，先执行conda config –set show_channel_urls yes生成该文件之后再修改。<br>将.condarc文件中的代码修改为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">channel_alias: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda</span><br><span class="line">default_channels:</span><br><span class="line">  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main</span><br><span class="line">  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free</span><br><span class="line">  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;r</span><br><span class="line">  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;pro</span><br><span class="line">  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud</span><br><span class="line">  msys2: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud</span><br><span class="line">  bioconda: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud</span><br><span class="line">  menpo: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud</span><br><span class="line">  pytorch: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud</span><br><span class="line">  simpleitk: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud</span><br></pre></td></tr></table></figure>
<p>如果输入conda指令显示solve environment,在cmd输入下行代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda update -n base conda</span><br></pre></td></tr></table></figure>

<p>运行conda clean -i清除索引缓存，保证用的是镜像站提供的索引。<br>运行conda create -n myenv numpy测试一下。<br>这些命令都是在cmd中输入的。</p>
<p>使用：<br>1.点击Open Dir(打开图片所在文件夹).<br>2.点击Change Save Dir修改生成xml文件存储位置。<br>3.在edit里面找到create RectBox，或者右键选定create RectBox。<br>4.选取矩形框后可以自定义标签名字，也可以使用已经定义好的。<br>5.再按ctrl+s，就可以在save dir路径下找到这张图片对应的xml文件。<br>6.next image对下一张照片进行处理。<br>注：1.xml文件的名字默认是图片的名字<br>    2.不同版本的labelImg在界面上会有稍微的区别<br>    3.标注过程中可随时返回进行修改，后保存的文件会覆盖之前的。<br>    4.labelImg既可以标注VOC格式的数据集，也可以标注YOLO格式的数据集。</p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-制作tensorflow数据集：xml转csv到tfrecord" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/20/%E5%88%B6%E4%BD%9Ctensorflow%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9Axml%E8%BD%ACcsv%E5%88%B0tfrecord/"
    >制作tensorflow数据集：xml转csv到tfrecord</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/20/%E5%88%B6%E4%BD%9Ctensorflow%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9Axml%E8%BD%ACcsv%E5%88%B0tfrecord/" class="article-date">
  <time datetime="2020-03-20T13:48:06.000Z" itemprop="datePublished">2020-03-20</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>将xml文件转换成csv文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import pandas as pd</span><br><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def xml_to_csv(path):</span><br><span class="line">    xml_list &#x3D; []</span><br><span class="line">    for xml_file in glob.glob(path + &#39;&#x2F;*.xml&#39;):</span><br><span class="line">        tree &#x3D; ET.parse(xml_file)</span><br><span class="line">        root &#x3D; tree.getroot()</span><br><span class="line">        for member in root.findall(&#39;object&#39;):</span><br><span class="line">            value &#x3D; (root.find(&#39;filename&#39;).text,</span><br><span class="line">                     int(root.find(&#39;size&#39;)[0].text),</span><br><span class="line">                     int(root.find(&#39;size&#39;)[1].text),</span><br><span class="line">                     member[0].text,</span><br><span class="line">                     int(member[4][0].text),</span><br><span class="line">                     int(member[4][1].text),</span><br><span class="line">                     int(member[4][2].text),</span><br><span class="line">                     int(member[4][3].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name &#x3D; [&#39;filename&#39;, &#39;width&#39;, &#39;height&#39;, &#39;class&#39;, &#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]</span><br><span class="line">    xml_df &#x3D; pd.DataFrame(xml_list, columns&#x3D;column_name)</span><br><span class="line">    return xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    for folder in [&#39;train&#39;,&#39;test&#39;]:</span><br><span class="line">        image_path &#x3D; os.path.join(os.getcwd(), (&#39;images&#x2F;&#39; + folder))  # 这里就是需要访问的.xml的存放地址</span><br><span class="line">        xml_df &#x3D; xml_to_csv(image_path)                               # object_detection&#x2F;images&#x2F;train or test</span><br><span class="line">        xml_df.to_csv((&#39;images&#x2F;&#39; + folder + &#39;_labels.csv&#39;), index&#x3D;None)</span><br><span class="line">        print(&#39;Successfully converted xml to csv.&#39;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p>上述代码命名为xml_to_csv.py，在xml_to_csv.py同级目录下建立一个images文件夹，并且建立两个子文件夹train和test。train和test文件夹中放着jpg文件和对应的xml文件。运行上述代码，将在images文件夹下产生两个.csv文件，分别为train_labels.csv和test_labels.csv。</p>
<p>将csv文件转换成TFRecord文件：<br>在上一步完成后，再运行下面代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">Usage:</span><br><span class="line">  # From tensorflow&#x2F;models&#x2F;</span><br><span class="line">  # Create train data:</span><br><span class="line">  python generate_tfrecord.py --csv_input&#x3D;images&#x2F;train_labels.csv --image_dir&#x3D;images&#x2F;train --output_path&#x3D;train.record</span><br><span class="line"></span><br><span class="line">  # Create test data:</span><br><span class="line">  python generate_tfrecord.py --csv_input&#x3D;images&#x2F;test_labels.csv  --image_dir&#x3D;images&#x2F;test --output_path&#x3D;test.record</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">from __future__ import division</span><br><span class="line">from __future__ import print_function</span><br><span class="line">from __future__ import absolute_import</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import io</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">from PIL import Image</span><br><span class="line">from object_detection.utils import dataset_util</span><br><span class="line">from collections import namedtuple, OrderedDict</span><br><span class="line"></span><br><span class="line">flags &#x3D; tf.app.flags</span><br><span class="line">flags.DEFINE_string(&#39;csv_input&#39;, &#39;&#39;, &#39;Path to the CSV input&#39;)</span><br><span class="line">flags.DEFINE_string(&#39;image_dir&#39;, &#39;&#39;, &#39;Path to the image directory&#39;)</span><br><span class="line">flags.DEFINE_string(&#39;output_path&#39;, &#39;&#39;, &#39;Path to output TFRecord&#39;)</span><br><span class="line">FLAGS &#x3D; flags.FLAGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># M1，this code part need to be modified according to your real situation</span><br><span class="line">def class_text_to_int(row_label):</span><br><span class="line">    if row_label &#x3D;&#x3D; &#39;nine&#39;:</span><br><span class="line">        return 1</span><br><span class="line">    elif row_label &#x3D;&#x3D; &#39;ten&#39;:</span><br><span class="line">        return 2</span><br><span class="line">    elif row_label &#x3D;&#x3D; &#39;jack&#39;:</span><br><span class="line">        return 3</span><br><span class="line">    elif row_label &#x3D;&#x3D; &#39;queen&#39;:</span><br><span class="line">        return 4</span><br><span class="line">    elif row_label &#x3D;&#x3D; &#39;king&#39;:</span><br><span class="line">        return 5</span><br><span class="line">    elif row_label &#x3D;&#x3D; &#39;ace&#39;:</span><br><span class="line">        return 6</span><br><span class="line">    else:</span><br><span class="line">        return 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def split(df, group):</span><br><span class="line">    data &#x3D; namedtuple(&#39;data&#39;, [&#39;filename&#39;, &#39;object&#39;])</span><br><span class="line">    gb &#x3D; df.groupby(group)</span><br><span class="line">    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_tf_example(group, path):</span><br><span class="line">    with tf.gfile.GFile(os.path.join(path, &#39;&#123;&#125;&#39;.format(group.filename)), &#39;rb&#39;) as fid:</span><br><span class="line">        encoded_jpg &#x3D; fid.read()</span><br><span class="line">    encoded_jpg_io &#x3D; io.BytesIO(encoded_jpg)</span><br><span class="line">    image &#x3D; Image.open(encoded_jpg_io)</span><br><span class="line">    width, height &#x3D; image.size</span><br><span class="line"></span><br><span class="line">    filename &#x3D; group.filename.encode(&#39;utf8&#39;)</span><br><span class="line">    image_format &#x3D; b&#39;jpg&#39;</span><br><span class="line">    xmins &#x3D; []</span><br><span class="line">    xmaxs &#x3D; []</span><br><span class="line">    ymins &#x3D; []</span><br><span class="line">    ymaxs &#x3D; []</span><br><span class="line">    classes_text &#x3D; []</span><br><span class="line">    classes &#x3D; []</span><br><span class="line"></span><br><span class="line">    for index, row in group.object.iterrows():</span><br><span class="line">        xmins.append(row[&#39;xmin&#39;] &#x2F; width)</span><br><span class="line">        xmaxs.append(row[&#39;xmax&#39;] &#x2F; width)</span><br><span class="line">        ymins.append(row[&#39;ymin&#39;] &#x2F; height)</span><br><span class="line">        ymaxs.append(row[&#39;ymax&#39;] &#x2F; height)</span><br><span class="line">        classes_text.append(row[&#39;class&#39;].encode(&#39;utf8&#39;))</span><br><span class="line">        classes.append(class_text_to_int(row[&#39;class&#39;]))</span><br><span class="line"></span><br><span class="line">    tf_example &#x3D; tf.train.Example(features&#x3D;tf.train.Features(feature&#x3D;&#123;</span><br><span class="line">        &#39;image&#x2F;height&#39;: dataset_util.int64_feature(height),</span><br><span class="line">        &#39;image&#x2F;width&#39;: dataset_util.int64_feature(width),</span><br><span class="line">        &#39;image&#x2F;filename&#39;: dataset_util.bytes_feature(filename),</span><br><span class="line">        &#39;image&#x2F;source_id&#39;: dataset_util.bytes_feature(filename),</span><br><span class="line">        &#39;image&#x2F;encoded&#39;: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        &#39;image&#x2F;format&#39;: dataset_util.bytes_feature(image_format),</span><br><span class="line">        &#39;image&#x2F;object&#x2F;bbox&#x2F;xmin&#39;: dataset_util.float_list_feature(xmins),</span><br><span class="line">        &#39;image&#x2F;object&#x2F;bbox&#x2F;xmax&#39;: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        &#39;image&#x2F;object&#x2F;bbox&#x2F;ymin&#39;: dataset_util.float_list_feature(ymins),</span><br><span class="line">        &#39;image&#x2F;object&#x2F;bbox&#x2F;ymax&#39;: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        &#39;image&#x2F;object&#x2F;class&#x2F;text&#39;: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        &#39;image&#x2F;object&#x2F;class&#x2F;label&#39;: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    return tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main(_):</span><br><span class="line">    writer &#x3D; tf.python_io.TFRecordWriter(FLAGS.output_path)</span><br><span class="line">    path &#x3D; os.path.join(os.getcwd(), FLAGS.image_dir)</span><br><span class="line">    examples &#x3D; pd.read_csv(FLAGS.csv_input)</span><br><span class="line">    grouped &#x3D; split(examples, &#39;filename&#39;)</span><br><span class="line">    for group in grouped:</span><br><span class="line">        tf_example &#x3D; create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.SerializeToString())</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    output_path &#x3D; os.path.join(os.getcwd(), FLAGS.output_path)</span><br><span class="line">    print(&#39;Successfully created the TFRecords: &#123;&#125;&#39;.format(output_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>

<p>步骤如下：<br>    1.通过执行python xml_to_csv.py生成相应的.csv文件<br>    2.在同一目录下顺序执行下面两条语句<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python generate_tfrecord.py --csv_input&#x3D;images&#x2F;train_labels.csv --image_dir&#x3D;images&#x2F;train --output_path&#x3D;train.record</span><br><span class="line">python generate_tfrecord.py --csv_input&#x3D;images&#x2F;test_labels.csv  --image_dir&#x3D;images&#x2F;test --output_path&#x3D;test.record</span><br></pre></td></tr></table></figure></p>
<p>最终会产生两个tfrecord格式的文件。其中generate_tfrecord.py是上述代码的命名，csv_input=images/train_labels.csv是输入的.csv文件的路径，图片的存储路径是image_dir=images/train or test，输出的文件在当前目录文件夹下名称为train.record以及test.record。</p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-tensorflow2-0系列-十二-：模型导出" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E5%8D%81%E4%BA%8C-%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA/"
    >tensorflow2.0系列(十二)：模型导出</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E5%8D%81%E4%BA%8C-%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA/" class="article-date">
  <time datetime="2020-03-20T12:45:42.000Z" itemprop="datePublished">2020-03-20</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>使用SavedModel完整导出模型：<br>在部署模型时，我们的第一步往往是将训练好的整个模型完整导出为一系列标准格式的文件，然后即可在不同的平台上部署模型文件。这时，TensorFlow为我们提供了SavedModel这一格式。与前面介绍的Checkpoint不同，SavedModel包含了一个TensorFlow程序的完整信息：不仅包含参数的权值，还包含计算的流程（即计算图）。当模型导出为 SavedModel 文件时，无需建立模型的源代码即可再次运行模型，这使得SavedModel尤其适用于模型的分享和部署。后文的TensorFlow Serving（服务器端部署模型）、TensorFlow Lite（移动端部署模型）以及TensorFlow.js都会用到这一格式。<br>Keras模型均可方便地导出为SavedModel格式。不过需要注意的是，因为 SavedModel基于计算图，所以对于使用继承tf.keras.Model类建立的Keras模型，其需要导出到 SavedModel 格式的方法（比如call）都需要使用@tf.function修饰。然后，假设我们有一个名为model的Keras模型，使用下面的代码即可将模型导出为SavedModel：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.saved_model.save(model, &quot;保存的目标文件夹名称&quot;)</span><br></pre></td></tr></table></figure>

<p>在需要载入 SavedModel 文件时，使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; tf.saved_model.load(&quot;保存的目标文件夹名称&quot;)</span><br></pre></td></tr></table></figure>
<p>即可。</p>
<p>对于使用继承tf.keras.Model类建立的Keras模型model，使用SavedModel载入后将无法使用 model()直接进行推断，而需要使用model.call()。<br>以下是一个简单的示例，将前文MNIST手写体识别的模型进行导出和导入。导出模型到saved/1文件夹：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from zh.model.utils import MNISTLoader</span><br><span class="line"></span><br><span class="line">num_epochs &#x3D; 1</span><br><span class="line">batch_size &#x3D; 50</span><br><span class="line">learning_rate &#x3D; 0.001</span><br><span class="line"></span><br><span class="line">model &#x3D; tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(100, activation&#x3D;tf.nn.relu),</span><br><span class="line">    tf.keras.layers.Dense(10),</span><br><span class="line">    tf.keras.layers.Softmax()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">data_loader &#x3D; MNISTLoader()</span><br><span class="line">model.compile(</span><br><span class="line">    optimizer&#x3D;tf.keras.optimizers.Adam(learning_rate&#x3D;0.001),</span><br><span class="line">    loss&#x3D;tf.keras.losses.sparse_categorical_crossentropy,</span><br><span class="line">    metrics&#x3D;[tf.keras.metrics.sparse_categorical_accuracy]</span><br><span class="line">)</span><br><span class="line">model.fit(data_loader.train_data, data_loader.train_label, epochs&#x3D;num_epochs, batch_size&#x3D;batch_size)</span><br><span class="line">tf.saved_model.save(model, &quot;saved&#x2F;1&quot;)</span><br></pre></td></tr></table></figure>

<p>将saved/1中的模型导入并测试性能：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from zh.model.utils import MNISTLoader</span><br><span class="line"></span><br><span class="line">batch_size &#x3D; 50</span><br><span class="line"></span><br><span class="line">model &#x3D; tf.saved_model.load(&quot;saved&#x2F;1&quot;)</span><br><span class="line">data_loader &#x3D; MNISTLoader()</span><br><span class="line">sparse_categorical_accuracy &#x3D; tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">num_batches &#x3D; int(data_loader.num_test_data &#x2F;&#x2F; batch_size)</span><br><span class="line">for batch_index in range(num_batches):</span><br><span class="line">    start_index, end_index &#x3D; batch_index * batch_size, (batch_index + 1) * batch_size</span><br><span class="line">    y_pred &#x3D; model(data_loader.test_data[start_index: end_index])</span><br><span class="line">    sparse_categorical_accuracy.update_state(y_true&#x3D;data_loader.test_label[start_index: end_index], y_pred&#x3D;y_pred)</span><br><span class="line">print(&quot;test accuracy: %f&quot; % sparse_categorical_accuracy.result())</span><br></pre></td></tr></table></figure>

<p>输出:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test accuracy: 0.952000</span><br></pre></td></tr></table></figure>

<p>使用继承tf.keras.Model类建立的Keras模型同样可以以相同方法导出，唯须注意call方法需要以@tf.function修饰，以转化为SavedModel支持的计算图，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class MLP(tf.keras.Model):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.flatten &#x3D; tf.keras.layers.Flatten()</span><br><span class="line">        self.dense1 &#x3D; tf.keras.layers.Dense(units&#x3D;100, activation&#x3D;tf.nn.relu)</span><br><span class="line">        self.dense2 &#x3D; tf.keras.layers.Dense(units&#x3D;10)</span><br><span class="line"></span><br><span class="line">    @tf.function</span><br><span class="line">    def call(self, inputs):         # [batch_size, 28, 28, 1]</span><br><span class="line">        x &#x3D; self.flatten(inputs)    # [batch_size, 784]</span><br><span class="line">        x &#x3D; self.dense1(x)          # [batch_size, 100]</span><br><span class="line">        x &#x3D; self.dense2(x)          # [batch_size, 10]</span><br><span class="line">        output &#x3D; tf.nn.softmax(x)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">model &#x3D; MLP()</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>模型导入并测试性能的过程也相同，唯须注意模型推断时需要显式调用call方法，即使用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">y_pred &#x3D; model.call(data_loader.test_data[start_index: end_index])</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-tensorflow2-0系列-十一-：GPU的使用与分配" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E5%8D%81%E4%B8%80-%EF%BC%9AGPU%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%88%86%E9%85%8D/"
    >tensorflow2.0系列(十一)：GPU的使用与分配</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E5%8D%81%E4%B8%80-%EF%BC%9AGPU%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%88%86%E9%85%8D/" class="article-date">
  <time datetime="2020-03-20T10:04:26.000Z" itemprop="datePublished">2020-03-20</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>指定当前程序使用的GPU：<br>很多时候的场景是：实验室/公司研究组里有许多学生/研究员需要共同使用一台多GPU的工作站，而默认情况下TensorFlow会使用其所能够使用的所有GPU，这时就需要合理分配显卡资源。<br>首先，通过tf.config.experimental.list_physical_devices，我们可以获得当前主机上某种特定运算设备类型（如GPU或CPU）的列表，例如，在一台具有4块GPU和一个CPU的工作站上运行以下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpus &#x3D; tf.config.experimental.list_physical_devices(device_type&#x3D;&#39;GPU&#39;)</span><br><span class="line">cpus &#x3D; tf.config.experimental.list_physical_devices(device_type&#x3D;&#39;CPU&#39;)</span><br><span class="line">print(gpus, cpus)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[PhysicalDevice(name&#x3D;&#39;&#x2F;physical_device:GPU:0&#39;, device_type&#x3D;&#39;GPU&#39;),</span><br><span class="line"> PhysicalDevice(name&#x3D;&#39;&#x2F;physical_device:GPU:1&#39;, device_type&#x3D;&#39;GPU&#39;),</span><br><span class="line"> PhysicalDevice(name&#x3D;&#39;&#x2F;physical_device:GPU:2&#39;, device_type&#x3D;&#39;GPU&#39;),</span><br><span class="line"> PhysicalDevice(name&#x3D;&#39;&#x2F;physical_device:GPU:3&#39;, device_type&#x3D;&#39;GPU&#39;)]</span><br><span class="line">[PhysicalDevice(name&#x3D;&#39;&#x2F;physical_device:CPU:0&#39;, device_type&#x3D;&#39;CPU&#39;)]</span><br></pre></td></tr></table></figure>
<p>可见，该工作站具有4块GPU：GPU:0、GPU:1、GPU:2、GPU:3，以及一个CPU：CPU:0。<br>然后，通过tf.config.experimental.set_visible_devices，可以设置当前程序可见的设备范围（当前程序只会使用自己可见的设备，不可见的设备不会被当前程序使用）。例如，如果在上述4卡的机器中我们需要限定当前程序只使用下标为0、1的两块显卡（GPU:0和GPU:1），可以使用以下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpus &#x3D; tf.config.experimental.list_physical_devices(device_type&#x3D;&#39;GPU&#39;)</span><br><span class="line">tf.config.experimental.set_visible_devices(devices&#x3D;gpus[0:2], device_type&#x3D;&#39;GPU&#39;)</span><br></pre></td></tr></table></figure>
<p>设置显存使用策略：<br>默认情况下，TensorFlow将使用几乎所有可用的显存，以避免内存碎片化所带来的性能损失。不过，TensorFlow提供两种显存使用策略，让我们能够更灵活地控制程序的显存使用方式：<br>仅在需要时申请显存空间（程序初始运行时消耗很少的显存，随着程序的运行而动态申请显存）；<br>限制消耗固定大小的显存（程序不会超出限定的显存大小，若超出则报错）。<br>可以通过tf.config.experimental.set_memory_growth将GPU的显存使用策略设置为 “仅在需要时申请显存空间”。以下代码将所有GPU设置为仅在需要时申请显存空间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpus &#x3D; tf.config.experimental.list_physical_devices(device_type&#x3D;&#39;GPU&#39;)</span><br><span class="line">for gpu in gpus:</span><br><span class="line">    tf.config.experimental.set_memory_growth(device&#x3D;gpu, enable&#x3D;True)</span><br></pre></td></tr></table></figure>

<p>以下代码通过tf.config.experimental.set_virtual_device_configuration选项并传入tf.config.experimental.VirtualDeviceConfiguration实例，设置TensorFlow固定消耗GPU:0的1GB显存（其实可以理解为建立了一个显存大小为1GB的“虚拟 GPU”）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gpus &#x3D; tf.config.experimental.list_physical_devices(device_type&#x3D;&#39;GPU&#39;)</span><br><span class="line">tf.config.experimental.set_virtual_device_configuration(</span><br><span class="line">    gpus[0],</span><br><span class="line">    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit&#x3D;1024)])</span><br></pre></td></tr></table></figure>

<p>TensorFlow1.X的图执行模式下，可以在实例化新的session时传入tf.compat.v1.ConfigPhoto类来设置TensorFlow使用显存的策略。具体方式是实例化一个tf.ConfigProto类，设置参数，并在创建tf.compat.v1.Session 时指定Config参数。以下代码通过allow_growth选项设置TensorFlow仅在需要时申请显存空间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config &#x3D; tf.compat.v1.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth &#x3D; True</span><br><span class="line">sess &#x3D; tf.compat.v1.Session(config&#x3D;config)</span><br></pre></td></tr></table></figure>
<p>以下代码通过per_process_gpu_memory_fraction选项设置TensorFlow固定消耗40%的GPU显存：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config &#x3D; tf.compat.v1.ConfigProto()</span><br><span class="line">config.gpu_options.per_process_gpu_memory_fraction &#x3D; 0.4</span><br><span class="line">tf.compat.v1.Session(config&#x3D;config)</span><br></pre></td></tr></table></figure>

<p>单GPU模拟多GPU环境：<br>当我们的本地开发环境只有一个GPU，但却需要编写多GPU的程序在工作站上进行训练任务时，TensorFlow为我们提供了一个方便的功能，可以让我们在本地开发环境中建立多个模拟GPU，从而让多 GPU 的程序调试变得更加方便。以下代码在实体GPU：GPU:0的基础上建立了两个显存均为2GB的虚拟GPU。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gpus &#x3D; tf.config.experimental.list_physical_devices(&#39;GPU&#39;)</span><br><span class="line">tf.config.experimental.set_virtual_device_configuration(</span><br><span class="line">    gpus[0],</span><br><span class="line">    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit&#x3D;2048),</span><br><span class="line">     tf.config.experimental.VirtualDeviceConfiguration(memory_limit&#x3D;2048)])</span><br></pre></td></tr></table></figure>
<p>我们在单机多卡训练的代码前加入以上代码，即可让原本为多GPU设计的代码在单GPU环境下运行。当输出设备数量时，程序会输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Number of devices: 2</span><br></pre></td></tr></table></figure>
      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-tensorflow2-0系列-十-：TFRecord" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E5%8D%81-%EF%BC%9ATFRecord/"
    >tensorflow2.0系列(十)：TFRecord</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E5%8D%81-%EF%BC%9ATFRecord/" class="article-date">
  <time datetime="2020-03-20T09:27:17.000Z" itemprop="datePublished">2020-03-20</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>TFRecord是TensorFlow中的数据集存储格式。当我们将数据集整理成TFRecord格式后，TensorFlow就可以高效地读取和处理这些数据集，从而帮助我们更高效地进行大规模的模型训练。<br>TFRecord可以理解为一系列序列化的tf.train.Example元素所组成的列表文件，而每一个tf.train.Example又由若干个tf.train.Feature的字典组成。形式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># dataset.tfrecords</span><br><span class="line">[</span><br><span class="line">    &#123;   # example 1 (tf.train.Example)</span><br><span class="line">        &#39;feature_1&#39;: tf.train.Feature,</span><br><span class="line">        ...</span><br><span class="line">        &#39;feature_k&#39;: tf.train.Feature</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">    &#123;   # example N (tf.train.Example)</span><br><span class="line">        &#39;feature_1&#39;: tf.train.Feature,</span><br><span class="line">        ...</span><br><span class="line">        &#39;feature_k&#39;: tf.train.Feature</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>为了将形式各样的数据集整理为TFRecord格式，我们可以对数据集中的每个元素进行以下步骤：<br>读取该数据元素到内存；<br>将该元素转换为tf.train.Example对象（每一个tf.train.Example由若干个tf.train.Feature的字典组成，因此需要先建立Feature的字典）；<br>将该tf.train.Example对象序列化为字符串，并通过一个预先定义的tf.io.TFRecordWriter写入TFRecord文件。</p>
<p>而读取TFRecord数据则可按照以下步骤：<br>通过tf.data.TFRecordDataset读入原始的TFRecord文件,获得一个tf.data.Dataset数据集对象(此时该数据集对象中的tf.train.Example对象尚未被反序列化)；<br>通过Dataset.map方法，对该数据集对象中的每一个序列化的tf.train.Example字符串执行tf.io.parse_single_example函数，从而实现反序列化。</p>
<p>以下我们通过一个实例，展示将上一节中使用的cats_vs_dogs二分类数据集的训练集部分转换为TFRecord文件，并读取该文件的过程。<br>将数据集存储为 TFRecord 文件：<br>首先，与上一节类似，我们进行一些准备工作，下载数据集并解压到data_dir，初始化数据集的图片文件名列表及标签。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">data_dir &#x3D; &#39;C:&#x2F;datasets&#x2F;cats_vs_dogs&#39;</span><br><span class="line">train_cats_dir &#x3D; data_dir + &#39;&#x2F;train&#x2F;cats&#x2F;&#39;</span><br><span class="line">train_dogs_dir &#x3D; data_dir + &#39;&#x2F;train&#x2F;dogs&#x2F;&#39;</span><br><span class="line">tfrecord_file &#x3D; data_dir + &#39;&#x2F;train&#x2F;train.tfrecords&#39;</span><br><span class="line"></span><br><span class="line">train_cat_filenames &#x3D; [train_cats_dir + filename for filename in os.listdir(train_cats_dir)]</span><br><span class="line">train_dog_filenames &#x3D; [train_dogs_dir + filename for filename in os.listdir(train_dogs_dir)]</span><br><span class="line">train_filenames &#x3D; train_cat_filenames + train_dog_filenames</span><br><span class="line">train_labels &#x3D; [0] * len(train_cat_filenames) + [1] * len(train_dog_filenames)  # 将 cat 类的标签设为0，dog 类的标签设为1</span><br></pre></td></tr></table></figure>

<p>然后，通过以下代码，迭代读取每张图片，建立tf.train.Feature字典和tf.train.Example对象，序列化并写入TFRecord文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">with tf.io.TFRecordWriter(tfrecord_file) as writer:</span><br><span class="line">    for filename, label in zip(train_filenames, train_labels):</span><br><span class="line">        image &#x3D; open(filename, &#39;rb&#39;).read()     # 读取数据集图片到内存，image 为一个 Byte 类型的字符串</span><br><span class="line">        feature &#x3D; &#123;                             # 建立 tf.train.Feature 字典</span><br><span class="line">            &#39;image&#39;: tf.train.Feature(bytes_list&#x3D;tf.train.BytesList(value&#x3D;[image])),  # 图片是一个 Bytes 对象</span><br><span class="line">            &#39;label&#39;: tf.train.Feature(int64_list&#x3D;tf.train.Int64List(value&#x3D;[label]))   # 标签是一个 Int 对象</span><br><span class="line">        &#125;</span><br><span class="line">        example &#x3D; tf.train.Example(features&#x3D;tf.train.Features(feature&#x3D;feature)) # 通过字典建立 Example</span><br><span class="line">        writer.write(example.SerializeToString())   # 将Example序列化并写入 TFRecord 文件</span><br></pre></td></tr></table></figure>

<p>值得注意的是，tf.train.Feature支持三种数据格式：<br>tf.train.BytesList：字符串或原始Byte文件（如图片），通过bytes_list参数传入一个由字符串数组初始化的tf.train.BytesList对象；tf.train.FloatList ：浮点数，通过float_list参数传入一个由浮点数数组初始化的tf.train.FloatList对象；tf.train.Int64List ：整数，通过int64_list参数传入一个由整数数组初始化的tf.train.Int64List对象。如果只希望保存一个元素而非数组，传入一个只有一个元素的数组即可。运行以上代码，不出片刻，我们即可在tfrecord_file所指向的文件地址获得一个500MB左右的train.tfrecords文件。<br>读取TFRecord文件：<br>我们可以通过以下代码，读取之前建立的train.tfrecords文件，并通过Dataset.map方法，使用tf.io.parse_single_example函数对数据集中的每一个序列化的tf.train.Example对象解码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">raw_dataset &#x3D; tf.data.TFRecordDataset(tfrecord_file)    # 读取 TFRecord 文件</span><br><span class="line"></span><br><span class="line">feature_description &#x3D; &#123; # 定义Feature结构，告诉解码器每个Feature的类型是什么</span><br><span class="line">    &#39;image&#39;: tf.io.FixedLenFeature([], tf.string),</span><br><span class="line">    &#39;label&#39;: tf.io.FixedLenFeature([], tf.int64),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">def _parse_example(example_string): # 将 TFRecord 文件中的每一个序列化的 tf.train.Example 解码</span><br><span class="line">    feature_dict &#x3D; tf.io.parse_single_example(example_string, feature_description)</span><br><span class="line">    feature_dict[&#39;image&#39;] &#x3D; tf.io.decode_jpeg(feature_dict[&#39;image&#39;])    # 解码JPEG图片</span><br><span class="line">    return feature_dict[&#39;image&#39;], feature_dict[&#39;label&#39;]</span><br><span class="line"></span><br><span class="line">dataset &#x3D; raw_dataset.map(_parse_example)</span><br></pre></td></tr></table></figure>
<p>这里的feature_description类似于一个数据集的“描述文件”，通过一个由键值对组成的字典，告知tf.io.parse_single_example函数每个tf.train.Example数据项有哪些Feature，以及这些Feature的类型、形状等属性。tf.io.FixedLenFeature的三个输入参数shape、dtype和default_value（可省略）为每个Feature的形状、类型和默认值。这里我们的数据项都是单个的数值或者字符串，所以shape为空数组。</p>
<p>运行以上代码后，我们获得一个数据集对象dataset，这已经是一个可以用于训练的tf.data.Dataset对象了！我们从该数据集中读取元素并输出验证：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt </span><br><span class="line"></span><br><span class="line">for image, label in dataset:</span><br><span class="line">    plt.title(&#39;cat&#39; if label &#x3D;&#x3D; 0 else &#39;dog&#39;)</span><br><span class="line">    plt.imshow(image.numpy())</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>经验证，图片和标签都正确显示，数据集构建成功。</p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-tensorflow2-0系列-九-：数据集的构建与预处理" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E4%B9%9D-%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86/"
    >tensorflow2.0系列(九)：数据集的构建与预处理</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/03/20/tensorflow2-0%E7%B3%BB%E5%88%97-%E4%B9%9D-%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86/" class="article-date">
  <time datetime="2020-03-20T06:33:46.000Z" itemprop="datePublished">2020-03-20</time>
</a>
      
      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>很多时候，我们希望使用自己的数据集来训练模型。然而，面对一堆格式不一的原始数据文件，将其预处理并读入程序的过程往往十分繁琐，甚至比模型的设计还要耗费精力。比如，为了读入一批图像文件，我们可能需要纠结于python的各种图像处理包（比如pillow），自己设计 Batch 的生成方式，最后还可能在运行的效率上不尽如人意。为此，TensorFlow提供了tf.data这一模块，包括了一套灵活的数据集构建 API，能够帮助我们快速、高效地构建数据输入的流水线，尤其适用于数据量巨大的场景。<br>数据集对象的建立：<br>tf.data的核心是tf.data.Dataset类，提供了对数据集的高层封装。tf.data.Dataset由一系列的可迭代访问的元素（element）组成，每个元素包含一个或多个张量。比如说，对于一个由图像组成的数据集，每个元素可以是一个形状为长×宽×通道数的图片张量，也可以是由图片张量和图片标签张量组成的元组（Tuple）。<br>最基础的建立tf.data.Dataset的方法是使用tf.data.Dataset.from_tensor_slices()，适用于数据量较小（能够整个装进内存）的情况。具体而言，如果我们的数据集中的所有元素通过张量的第0维，拼接成一个大的张量（例如，前节的MNIST数据集的训练集即为一个[60000,28,28,1]的张量，表示了60000张28*28的单通道灰度图像），那么我们提供一个这样的张量或者第0维大小相同的多个张量作为输入，即可按张量的第0维展开来构建数据集，数据集的元素数量为张量第0位的大小。具体示例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">X &#x3D; tf.constant([2013, 2014, 2015, 2016, 2017])</span><br><span class="line">Y &#x3D; tf.constant([12000, 14000, 15000, 16500, 17500])</span><br><span class="line"></span><br><span class="line"># 也可以使用NumPy数组，效果相同</span><br><span class="line"># X &#x3D; np.array([2013, 2014, 2015, 2016, 2017])</span><br><span class="line"># Y &#x3D; np.array([12000, 14000, 15000, 16500, 17500])</span><br><span class="line"></span><br><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices((X, Y))</span><br><span class="line"></span><br><span class="line">for x, y in dataset:</span><br><span class="line">    print(x.numpy(), y.numpy())</span><br></pre></td></tr></table></figure>
<p>当提供多个张量作为输入时，张量的第0维大小必须相同，且必须将多个张量作为元组（Tuple，即使用Python中的小括号）拼接并作为输入。<br>以上一节的MNIST数据集为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt </span><br><span class="line"></span><br><span class="line">(train_data, train_label), (_, _) &#x3D; tf.keras.datasets.mnist.load_data()</span><br><span class="line">train_data &#x3D; np.expand_dims(train_data.astype(np.float32) &#x2F; 255.0, axis&#x3D;-1)      # [60000, 28, 28, 1]</span><br><span class="line">mnist_dataset &#x3D; tf.data.Dataset.from_tensor_slices((train_data, train_label))</span><br><span class="line"></span><br><span class="line">for image, label in mnist_dataset:</span><br><span class="line">    plt.title(label.numpy())</span><br><span class="line">    plt.imshow(image.numpy()[:, :, 0])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>高维数组的切片操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[:,0]是numpy中数组的一种写法，表示对一个二维数组，取该二维数组第一维中的所有数据，第二维中取第0个数据，直观来说，X[:,0]就是取所有行的第0个数据, X[:,1]就是取所有行的第1个数据。</span><br></pre></td></tr></table></figure>

<p>TensorFlow Datasets提供了一个基于tf.data.Datasets的开箱即用的数据集集合，相关内容可参考<a href="https://tf.wiki/zh/appendix/tfds.html" target="_blank" rel="noopener">TensorFlow Datasets</a>。例如，使用以下语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow_datasets as tfds</span><br><span class="line">dataset &#x3D; tfds.load(&quot;mnist&quot;, split&#x3D;tfds.Split.TRAIN)</span><br></pre></td></tr></table></figure>
<p>即可快速载入 MNIST 数据集。</p>
<p>对于特别巨大而无法完整载入内存的数据集，我们可以先将数据集处理为TFRecord格式，然后使用tf.data.TFRocrdDataset()进行载入。详情请参考下一节。<br>数据集对象的预处理：<br>tf.data.Dataset类为我们提供了多种数据集预处理方法。最常用的有：<br>Dataset.map(f)：对数据集中的每个元素应用函数f，得到一个新的数据集（这部分往往结合tf.io进行读写和解码文件，tf.image进行图像处理）；<br>Dataset.shuffle(buffer_size)：将数据集打乱（设定一个固定大小的缓冲区（Buffer），取出前 buffer_size个元素放入，并从缓冲区中随机采样，采样后的数据用后续数据替换）；<br>Dataset.batch(batch_size)：将数据集分成批次，即对每batch_size个元素，使用tf.stack()在第0维合并，成为一个元素；<br>除此以外，还有Dataset.repeat()（重复数据集的元素）、Dataset.reduce()（与 Map 相对的聚合操作）、Dataset.take()（截取数据集中的前若干个元素）等，可参考<a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset" target="_blank" rel="noopener">API文档</a> 进一步了解。</p>
<p>以下以 MNIST 数据集进行示例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def rot90(image, label):</span><br><span class="line">    image &#x3D; tf.image.rot90(image)</span><br><span class="line">    return image, label</span><br><span class="line"></span><br><span class="line">mnist_dataset &#x3D; mnist_dataset.map(rot90)</span><br><span class="line"></span><br><span class="line">for image, label in mnist_dataset:</span><br><span class="line">    plt.title(label.numpy())</span><br><span class="line">    plt.imshow(image.numpy()[:, :, 0])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>使用Dataset.batch()将数据集划分批次，每个批次的大小为4：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mnist_dataset &#x3D; mnist_dataset.batch(4)</span><br><span class="line"></span><br><span class="line">for images, labels in mnist_dataset:    # image: [4, 28, 28, 1], labels: [4]</span><br><span class="line">    fig, axs &#x3D; plt.subplots(1, 4)</span><br><span class="line">    for i in range(4):</span><br><span class="line">        axs[i].set_title(labels.numpy()[i])</span><br><span class="line">        axs[i].imshow(images.numpy()[i, :, :, 0])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>使用Dataset.shuffle()将数据打散后再设置批次，缓存大小设置为 10000：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mnist_dataset &#x3D; mnist_dataset.shuffle(buffer_size&#x3D;10000).batch(4)</span><br><span class="line"></span><br><span class="line">for images, labels in mnist_dataset:</span><br><span class="line">    fig, axs &#x3D; plt.subplots(1, 4)</span><br><span class="line">    for i in range(4):</span><br><span class="line">        axs[i].set_title(labels.numpy()[i])</span><br><span class="line">        axs[i].imshow(images.numpy()[i, :, :, 0])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>经测试，第一次运行和第二次运行的结果不同，可见每次的数据都会被随机打散。</p>
<p>Dataset.shuffle()时缓冲区大小buffer_size的设置：<br>tf.data.Dataset作为一个针对大规模数据设计的迭代器，本身无法方便地获得自身元素的数量或随机访问元素。因此，为了高效且较为充分地打散数据集，需要一些特定的方法。Dataset.shuffle()采取了以下方法：<br>设定一个固定大小为buffer_size的缓冲区（Buffer）；<br>初始化时，取出数据集中的前buffer_size个元素放入缓冲区；<br>每次需要从数据集中取元素时，即从缓冲区中随机采样一个元素并取出，然后从后续的元素中取出一个放回到之前被取出的位置，以维持缓冲区的大小。<br>因此，缓冲区的大小需要根据数据集的特性和数据排列顺序特点来进行合理的设置。比如：<br>当buffer_size设置为1时，其实等价于没有进行任何打散；<br>当数据集的标签顺序分布极为不均匀（例如二元分类时数据集前N个的标签为0，后N个的标签为1）时，较小的缓冲区大小会使得训练时取出的Batch数据很可能全为同一标签，从而影响训练效果。一般而言，数据集的顺序分布若较为随机，则缓冲区的大小可较小，否则则需要设置较大的缓冲区。</p>
<p>使用 tf.data 的并行化策略提高训练流程效率：<br>当训练模型时，我们希望充分利用计算资源，减少CPU/GPU的空载时间。然而有时，数据集的准备处理非常耗时，使得我们在每进行一次训练前都需要花费大量的时间准备待训练的数据，而此时GPU只能空载而等待数据，造成了计算资源的浪费，如下图所示：<br>[1]</p>
<p>数据集元素的获取与使用:<br>构建好数据并预处理后，我们需要从其中迭代获取数据以用于训练。tf.data.Dataset是一个Python的可迭代对象，因此可以使用For循环迭代获取数据，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices((A, B, C, ...))</span><br><span class="line">for a, b, c, ... in dataset:</span><br><span class="line">    # 对张量a, b, c等进行操作，例如送入模型进行训练</span><br></pre></td></tr></table></figure>

<p>也可以使用iter()显式创建一个Python迭代器并使用next()获取下一个元素，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices((A, B, C, ...))</span><br><span class="line">it &#x3D; iter(dataset)</span><br><span class="line">a_0, b_0, c_0, ... &#x3D; next(it)</span><br><span class="line">a_1, b_1, c_1, ... &#x3D; next(it)</span><br></pre></td></tr></table></figure>

<p>[2]</p>
<p>实例：cats_vs_dogs图像分类:<br>以下代码以猫狗图片二分类任务为示例，展示了使用tf.data结合tf.io和tf.image建立tf.data.Dataset数据集，并进行训练和测试的完整过程。数据集可至<a href="https://www.floydhub.com/fastai/datasets/cats-vs-dogs" target="_blank" rel="noopener">这里</a>下载。使用前须将数据集解压到代码中data_dir所设置的目录（此处默认设置为C:/datasets/cats_vs_dogs，可根据自己的需求进行修改）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">num_epochs &#x3D; 10</span><br><span class="line">batch_size &#x3D; 32</span><br><span class="line">learning_rate &#x3D; 0.001</span><br><span class="line">data_dir &#x3D; &#39;C:&#x2F;datasets&#x2F;cats_vs_dogs&#39;</span><br><span class="line">train_cats_dir &#x3D; data_dir + &#39;&#x2F;train&#x2F;cats&#x2F;&#39;</span><br><span class="line">train_dogs_dir &#x3D; data_dir + &#39;&#x2F;train&#x2F;dogs&#x2F;&#39;</span><br><span class="line">test_cats_dir &#x3D; data_dir + &#39;&#x2F;valid&#x2F;cats&#x2F;&#39;</span><br><span class="line">test_dogs_dir &#x3D; data_dir + &#39;&#x2F;valid&#x2F;dogs&#x2F;&#39;</span><br><span class="line"></span><br><span class="line">未完待续</span><br></pre></td></tr></table></figure>
      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2015-2020
        John Doe
      </li>
      <li>
        
        Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <span>
  <i>PV:<span id="busuanzi_value_page_pv"></span></i>
  <i>UV:<span id="busuanzi_value_site_uv"></span></i>
</span>
        
      </li>
      
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
    <aside class="sidebar">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="畅院士的开山大弟子的博客"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="http://shenyu-vip.lofter.com" target="_blank" rel="noopener">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/share.js"></script>


<script src="/js/lazyload.min.js"></script>


<script>
  try {
    var typed = new Typed("#subtitle", {
      strings: ['面朝大海，春暖花开', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
      startDelay: 0,
      typeSpeed: 200,
      loop: true,
      backSpeed: 100,
      showCursor: true
    });
  } catch (err) {
  }

</script>





<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/js/ayer.js"></script>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>




<script src="/js/busuanzi-2.3.pure.min.js"></script>



<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.2/dist/jquery.fancybox.min.css">
<script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.2/dist/jquery.fancybox.min.js"></script>


    
  </div>
</body>

</html>